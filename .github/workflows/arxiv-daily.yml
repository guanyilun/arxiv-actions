name: 'arxiv-daily'

on:
  workflow_dispatch:
  schedule:
    - cron: '0 4 * * *'

jobs:
  arxiv-digest:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v3
      - name: set up python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: run crawler
        env:
          ENDPOINT: ${{ secrets.ENDPOINT }}
          KEY_ID: ${{ secrets.KEY_ID }}
          APPLICATION_KEY: ${{ secrets.APPLICATION_KEY }}
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          TZ: 'America/New_York'
        run: |
          python scripts/crawl.py
      - name: tldr digestion and make summary
        env:
          ENDPOINT: ${{ secrets.ENDPOINT }}
          KEY_ID: ${{ secrets.KEY_ID }}
          APPLICATION_KEY: ${{ secrets.APPLICATION_KEY }}
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          TZ: 'America/New_York'
        run: |
          python scripts/digest_tldr.py
      - name: make markdown summary
        run: |
          python scripts/make_summary.py
      - name: create issue
        uses: JasonEtco/create-an-issue@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TZ: 'America/New_York'
        with:
          filename: data/latest.md
